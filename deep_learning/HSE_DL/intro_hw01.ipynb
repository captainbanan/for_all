{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_upCOEI3Upu"
   },
   "source": [
    "# Введение в глубинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 1. Введение в PyTorch. Полносвязные нейронные сети.\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 05.10.2021\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 19.10.2021\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 23.10.2021\n",
    "\n",
    "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, где $M_{full}$ &mdash; полная оценка за работу без учета штрафа, а $t$ &mdash; время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше **8.5**, а если сдать перед самым жестким дедлайном, то ваш максимум &mdash; **5.22** балла.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит предсказывать год выпуска песни по некоторым звуковым признакам: [данные](https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd). В ячейках ниже находится код для загрузки данных. Обратите внимание, что обучающая и тестовая выборки располагаются в одном файле, поэтому НЕ меняйте ячейку, в которой производится деление данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "RI_eoe063VaP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7NgSZeU-7vgj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-20 21:36:16--  https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 64:ff9b::80c3:afc\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|64:ff9b::80c3:afc|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 211011981 (201M) [application/x-httpd-php]\n",
      "Saving to: ‘data.txt.zip’\n",
      "\n",
      "data.txt.zip        100%[===================>] 201.24M  20.4MB/s    in 12s     \n",
      "\n",
      "2021-10-20 21:36:29 (16.7 MB/s) - ‘data.txt.zip’ saved [211011981/211011981]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DSVJZzkJ7zZE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n",
       "1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
       "2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
       "3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
       "4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
       "\n",
       "         8         9   ...        81         82        83        84        85  \\\n",
       "0 -12.23257   7.83089  ...  13.01620  -54.40548  58.99367  15.37344   1.11144   \n",
       "1  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n",
       "2  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n",
       "3 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n",
       "4  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n",
       "\n",
       "         86         87        88         89        90  \n",
       "0 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
       "1 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
       "2  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
       "3  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
       "4  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.txt.zip', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515340</th>\n",
       "      <td>2006</td>\n",
       "      <td>51.28467</td>\n",
       "      <td>45.88068</td>\n",
       "      <td>22.19582</td>\n",
       "      <td>-5.53319</td>\n",
       "      <td>-3.61835</td>\n",
       "      <td>-16.36914</td>\n",
       "      <td>2.12652</td>\n",
       "      <td>5.18160</td>\n",
       "      <td>-8.66890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.81440</td>\n",
       "      <td>-3.75991</td>\n",
       "      <td>-30.92584</td>\n",
       "      <td>26.33968</td>\n",
       "      <td>-5.03390</td>\n",
       "      <td>21.86037</td>\n",
       "      <td>-142.29410</td>\n",
       "      <td>3.42901</td>\n",
       "      <td>-41.14721</td>\n",
       "      <td>-15.46052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515341</th>\n",
       "      <td>2006</td>\n",
       "      <td>49.87870</td>\n",
       "      <td>37.93125</td>\n",
       "      <td>18.65987</td>\n",
       "      <td>-3.63581</td>\n",
       "      <td>-27.75665</td>\n",
       "      <td>-18.52988</td>\n",
       "      <td>7.76108</td>\n",
       "      <td>3.56109</td>\n",
       "      <td>-2.50351</td>\n",
       "      <td>...</td>\n",
       "      <td>32.38589</td>\n",
       "      <td>-32.75535</td>\n",
       "      <td>-61.05473</td>\n",
       "      <td>56.65182</td>\n",
       "      <td>15.29965</td>\n",
       "      <td>95.88193</td>\n",
       "      <td>-10.63242</td>\n",
       "      <td>12.96552</td>\n",
       "      <td>92.11633</td>\n",
       "      <td>10.88815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515342</th>\n",
       "      <td>2006</td>\n",
       "      <td>45.12852</td>\n",
       "      <td>12.65758</td>\n",
       "      <td>-38.72018</td>\n",
       "      <td>8.80882</td>\n",
       "      <td>-29.29985</td>\n",
       "      <td>-2.28706</td>\n",
       "      <td>-18.40424</td>\n",
       "      <td>-22.28726</td>\n",
       "      <td>-4.52429</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.73598</td>\n",
       "      <td>-71.15954</td>\n",
       "      <td>-123.98443</td>\n",
       "      <td>121.26989</td>\n",
       "      <td>10.89629</td>\n",
       "      <td>34.62409</td>\n",
       "      <td>-248.61020</td>\n",
       "      <td>-6.07171</td>\n",
       "      <td>53.96319</td>\n",
       "      <td>-8.09364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515343</th>\n",
       "      <td>2006</td>\n",
       "      <td>44.16614</td>\n",
       "      <td>32.38368</td>\n",
       "      <td>-3.34971</td>\n",
       "      <td>-2.49165</td>\n",
       "      <td>-19.59278</td>\n",
       "      <td>-18.67098</td>\n",
       "      <td>8.78428</td>\n",
       "      <td>4.02039</td>\n",
       "      <td>-12.01230</td>\n",
       "      <td>...</td>\n",
       "      <td>67.16763</td>\n",
       "      <td>282.77624</td>\n",
       "      <td>-4.63677</td>\n",
       "      <td>144.00125</td>\n",
       "      <td>21.62652</td>\n",
       "      <td>-29.72432</td>\n",
       "      <td>71.47198</td>\n",
       "      <td>20.32240</td>\n",
       "      <td>14.83107</td>\n",
       "      <td>39.74909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515344</th>\n",
       "      <td>2005</td>\n",
       "      <td>51.85726</td>\n",
       "      <td>59.11655</td>\n",
       "      <td>26.39436</td>\n",
       "      <td>-5.46030</td>\n",
       "      <td>-20.69012</td>\n",
       "      <td>-19.95528</td>\n",
       "      <td>-6.72771</td>\n",
       "      <td>2.29590</td>\n",
       "      <td>10.31018</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.50511</td>\n",
       "      <td>-69.18291</td>\n",
       "      <td>60.58456</td>\n",
       "      <td>28.64599</td>\n",
       "      <td>-4.39620</td>\n",
       "      <td>-64.56491</td>\n",
       "      <td>-45.61012</td>\n",
       "      <td>-5.51512</td>\n",
       "      <td>32.35602</td>\n",
       "      <td>12.17352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515345 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
       "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
       "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
       "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
       "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
       "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
       "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
       "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
       "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
       "\n",
       "              7         8         9   ...        81         82         83  \\\n",
       "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
       "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
       "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
       "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
       "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
       "...          ...       ...       ...  ...       ...        ...        ...   \n",
       "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
       "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
       "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
       "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
       "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
       "\n",
       "               84        85        86         87        88         89  \\\n",
       "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
       "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
       "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
       "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
       "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
       "...           ...       ...       ...        ...       ...        ...   \n",
       "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
       "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
       "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
       "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
       "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
       "\n",
       "              90  \n",
       "0        2.26327  \n",
       "1       26.92061  \n",
       "2       -0.66345  \n",
       "3       18.85382  \n",
       "4       28.74903  \n",
       "...          ...  \n",
       "515340 -15.46052  \n",
       "515341  10.88815  \n",
       "515342  -8.09364  \n",
       "515343  39.74909  \n",
       "515344  12.17352  \n",
       "\n",
       "[515345 rows x 91 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "n4wnRJT1778j"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "train_size = 463715\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='0', ylabel='7'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter(0, 7, s=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_386JE_o5gOd"
   },
   "source": [
    "## Задание 0. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
    "\n",
    "Мы будем использовать RMSE как метрику качества. Для самого первого бейзлайна обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otwuisa56MLr"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ilBKYt6OdD"
   },
   "source": [
    "## Задание 1. (максимум 10 баллов)\n",
    "\n",
    "Реализуйте обучение и тестирование нейронной сети для предоставленного вам набора данных. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
    "\n",
    "- $\\text{RMSE} \\le 9.00 $ &mdash; 4 балла\n",
    "- $\\text{RMSE} \\le 8.90 $ &mdash; 6 баллов\n",
    "- $\\text{RMSE} \\le 8.80 $ &mdash; 8 баллов\n",
    "- $\\text{RMSE} \\le 8.75 $ &mdash; 10 баллов\n",
    "\n",
    "Есть несколько правил, которых вам нужно придерживаться:\n",
    "\n",
    "- Весь пайплайн обучения должен быть написан на PyTorch. При этом вы можете пользоваться другими библиотеками (`numpy`, `sklearn` и пр.), но только для обработки данных. То есть как угодно трансформировать данные и считать метрики с помощью этих библиотек можно, а импортировать модели из `sklearn` и выбивать с их помощью требуемое качество &mdash; нельзя. Также нельзя пользоваться библиотеками, для которых сам PyTorch является зависимостью.\n",
    "\n",
    "- Мы никак не ограничиваем ваш выбор архитектуры модели, но скорее всего вам будет достаточно полносвязной нейронной сети.\n",
    "\n",
    "- Для обучения запрещается использовать какие-либо иные данные, кроме обучающей выборки.\n",
    "\n",
    "- Ансамблирование моделей запрещено.\n",
    "\n",
    "### Полезные советы:\n",
    "\n",
    "- Очень вряд ли, что у вас с первого раза получится выбить качество на 10 баллов, поэтому пробуйте разные архитектуры, оптимизаторы и значения гиперпараметров. В идеале при запуске каждого нового эксперимента вы должны менять что-то одно, чтобы точно знать, как этот фактор влияет на качество.\n",
    "\n",
    "- Тот факт, что мы занимаемся глубинным обучением, не означает, что стоит забывать про приемы, использующиеся в классическом машинном обучении. Так что обязательно проводите исследовательский анализ данных, отрисовывайте нужные графики и не забывайте про масштабирование и подбор гиперпараметров.\n",
    "\n",
    "- Вы наверняка столкнетесь с тем, что ваша нейронная сеть будет сильно переобучаться. Для нейросетей существуют специальные методы регуляризации, например, dropout ([статья](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)) и weight decay ([блогпост](https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd)). Они, разумеется, реализованы в PyTorch. Попробуйте поэкспериментировать с ними.\n",
    "\n",
    "- Если вы чего-то не знайте, не гнушайтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению в целом и по PyTorch в частности. Но не забывайте, что за скатанный код без ссылки на источник придется ответить по всей строгости!\n",
    "\n",
    "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
    "\n",
    "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так!\n",
    "\n",
    "- Пользуйтесь утилитами, которые вам предоставляет PyTorch (например, Dataset и Dataloader). Их специально разработали для упрощения разработки пайплайна обучения.\n",
    "\n",
    "- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
    "\n",
    "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
    "\n",
    "**ОБЯЗАТЕЛЬНО** рисуйте графики зависимости лосса/метрики на обучающей и тестовой выборках в зависимости от времени обучения. Если обучение занимает относительно небольшое число эпох, то лучше рисовать зависимость от номера шага обучения, если же эпох больше, то рисуйте зависимость по эпохам. Если проверяющий не увидит такого графика для вашей лучшей модели, то он в праве снизить баллы за задание.\n",
    "\n",
    "**ВАЖНО!** Ваше решение должно быть воспроизводимым. Если это не так, то проверяющий имеет право снизить баллы за задание. Чтобы зафиксировать random seed, воспользуйтесь функцией из ячейки ниже.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "VaMButDmEKKw"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZW0gMe3vT8u"
   },
   "source": [
    "Вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться следующими сигнатурами функций. Лучше всего, если вы проверите ваши предсказания ассертом: так вы убережете себя от разных косяков, например, что вектор предсказаний состоит из всего одного числа. В любом случае, внимательно следите за тем, для каких тензоров вы считаете метрику RMSE. При случайном или намеренном введении в заблуждение проверяющие очень сильно разозлятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "peomNjMWbkSz"
   },
   "outputs": [],
   "source": [
    "train_set = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "train_loader = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "\n",
    "test_set = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "test_loader = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "\n",
    "model = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "optimizer = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "criterion = None # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def create_network():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module('linear1', nn.Linear(90, 180))\n",
    "    net.add_module('bn1', nn.BatchNorm1d(num_features=180))\n",
    "    net.add_module('relu1', nn.ReLU(inplace=True))\n",
    "    \n",
    "    net.add_module('linear2', nn.Linear(180, 300))\n",
    "    net.add_module('bn2', nn.BatchNorm1d(num_features=300))\n",
    "    net.add_module('relu2', nn.ReLU(inplace=True))\n",
    "    \n",
    "    net.add_module('linear3', nn.Linear(300, 100))\n",
    "    net.add_module('bn3', nn.BatchNorm1d(num_features=100))\n",
    "    net.add_module('relu3', nn.ReLU(inplace=True))\n",
    "    \n",
    "    net.add_module('linear_last', nn.Linear(100, 1))\n",
    "    \n",
    "    net.add_module('final', nn.Flatten())\n",
    "    \n",
    "    net = net.train(False)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch, net):\n",
    "    X_batch = torch.FloatTensor(X_batch).to(device=device)\n",
    "    y_batch = torch.FloatTensor(y_batch).to(device=device)\n",
    "    predict = net.to(device)(X_batch)\n",
    "    target = y_batch\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = torch.sqrt(criterion(y_batch, predict))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, Y, batch_size):\n",
    "    n_samples = X.shape[0]\n",
    "        \n",
    "    # Shuffle at the start of epoch\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_idx = indices[start:end]\n",
    "        yield X[batch_idx], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463715, 90)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only cpu :(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a2ff87c35a4a409882854492ac0598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9715c8031ba42dcbdc785e10475dd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/captainbanana/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([99, 1])) that is different to the input size (torch.Size([99])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-2f847d9c57b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# disable dropout / use averages for batch_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "net = create_network()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('only cpu :(')\n",
    "net.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "nets = []\n",
    "\n",
    "num_epochs = 50 # total amount of full passes over training data\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1\n",
    "\n",
    "for epoch in trange(num_epochs):\n",
    "    start_time = time.time()\n",
    "    net.train(True) # enable dropout / batch_norm training behavior\n",
    "    batch_num = 0\n",
    "    for X_batch, y_batch in tqdm(get_batches(X_train, y_train, batch_size_train)):\n",
    "        # train on batch\n",
    "        opt.zero_grad()\n",
    "        loss = compute_loss(X_batch, y_batch, net)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "        batch_num += 1\n",
    "    \n",
    "    net.train(False) # disable dropout / use averages for batch_norm\n",
    "    \n",
    "    nets.append(copy.deepcopy(net))\n",
    "    \n",
    "    for X_batch, y_batch in get_batches(X_test, y_test, X_test.shape[0]):\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        val_accuracy.append(loss)\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(auged_images_train) // batch_size :])))\n",
    "    print(\"  val  (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(val_loss[-len(auged_images_train) // batch_size :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(10.934179, dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for X_batch, y_batch in get_batches(X_test, y_test, X_test.shape[0]):\n",
    "    loss = compute_loss(X_batch, y_batch, net)\n",
    "    loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.4238, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8Wmxrf5Qveux"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, test_loader):\n",
    "    '''\n",
    "    params:\n",
    "        model - torch.nn.Module to be fitted\n",
    "        optimizer - model optimizer\n",
    "        criterion - loss function from torch.nn\n",
    "        train_loader - torch.utils.data.Dataloader with train set\n",
    "        test_loader - torch.utils.data.Dataloader with test set\n",
    "                      (if you wish to validate during training)\n",
    "    '''\n",
    "    # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "    raise NotImplementedError\n",
    "\n",
    "def test(model, criterion, test_loader):\n",
    "    '''\n",
    "    params:\n",
    "        model - torch.nn.Module to be evaluated on test set\n",
    "        criterion - loss function from torch.nn\n",
    "        test_loader - torch.utils.data.Dataloader with test set\n",
    "    ----------\n",
    "    returns:\n",
    "        predicts - torch.tensor with shape (len(test_loader.dataset), ),\n",
    "                   which contains predictions for test objects\n",
    "    '''\n",
    "    # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
    "    predicts = torch.ones(len(test_loader.dataset))\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4PVEXDgD6Swj"
   },
   "outputs": [],
   "source": [
    "assert test(model, criterion, test_loader).shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bine9EES6TIn"
   },
   "source": [
    "## Задание 2. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
    "\n",
    "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bk5pEwa66UZn"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro-hw01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
