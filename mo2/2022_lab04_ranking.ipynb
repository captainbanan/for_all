{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4. Ранжирование.\n",
    "\n",
    "\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 9 баллов. Сдавать задание после указанного в lk срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с данными\n",
    "\n",
    "### Ранжирование организаций по пользовательскому запросу\n",
    "\n",
    "Что мы обычно делаем, когда нам нужно найти определённое место, но не знаем его местоположения? Используем поиск на картах.\n",
    "\n",
    "В этой лабораторной работе вам будет необходимо построить небольшую поисковую систему, позволяющую отранжировать организации по запросу пользователя.\n",
    "\n",
    "Для обучения вам даны 2000 запросов и более 13 тысяч найденных по ним организаций. Для каждой пары \"запрос — организация\" была посчитана релевантность, по которой и происходит ранжирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла) Задание 1.** Загрузите [данные](https://disk.yandex.ru/d/Bf3P4H8FDYe7-g) о запросах и их релевантности (*train.csv*), а также информацию об организациях (*train_org_information.json*) и рубриках (*train_rubric_information.json*)\n",
    "\n",
    "Для дальнейших экспериментов необходимо посчитать небольшой набор базовых факторов. С использованием информации о запросах и организациях, посчитайте факторы, которые на ваш взгляд будут полезными для предсказания релевантности.\n",
    "\n",
    "Примерами текстовых факторов могут служить:\n",
    " - кол-во слов в запросе и названии организации;\n",
    " - пословные/N-граммные пересечения слов запроса и названия организации (также можно использовать синонимы названия организации и адрес организации): кол-во слов в пересечении, [мера Жаккара](https://en.wikipedia.org/wiki/Jaccard_index) и пр.;\n",
    " - кол-во различных синонимичных названий организации (поле *names* в описании организации);\n",
    " - One-hot-encoded язык запроса.\n",
    " \n",
    "По информации о географическом положении:\n",
    " - факт совпадения региона, где задавался запрос и региона организации;\n",
    " - координаты показанной области;\n",
    " - размеры показанной области;\n",
    " - меры, характеризующие близость координат организации к показанному окну: расстояние до центра области и другие.\n",
    " \n",
    "Факторы, описывающие организацию:\n",
    " - one-hot-encoding фактор cтраны или региона организации (важно: не используйте one-hot-encoding факторы, в которых больше 10 значений; если в факторе слишком много значений, ограничьтесь, например, только самыми популярными категориями)\n",
    " - кол-во рабочих дней в неделе и общая продолжительность работы (поле *work_intervals* в описании организации)\n",
    " - кол-во рубрик (поле *rubrics* в описании организации)\n",
    " \n",
    "![](https://miro.medium.com/max/1500/0*FwubnnoNlt6Coo9j.png)\n",
    "\n",
    "В этом задании не нужно использовать многомерные представления текстовой информации (tfidf и прочие embeddings) и информацию о кликах (*train_clicks_information.json*). Придумывать сверхсложные факторы тоже необязательно.\n",
    "\n",
    "Вы можете реализовать описанные выше факторы и/или придумать свои. Но зачастую такие простые признаки могут приносить наибольшую пользу.\n",
    "\n",
    "В итоге у вас должно получиться от 15 до 50 факторов, характеризующих запрос и организацию и покрывающих основные источники данных (кроме кликов). Это наш основной датасет, который будет использоваться в экспериментах.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from functools import partial\n",
    "import chardet\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import json\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ndcg_score\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import types\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "import sklearn\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from catboost import Pool, cv\n",
    "from catboost import CatBoostRanker, Pool, MetricVisualizer\n",
    "from copy import deepcopy\n",
    "import functools\n",
    "\n",
    "\n",
    "from geopy.distance import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "with open('ranking_data_shad/train_org_information.json') as f:\n",
    "    org_info = json.load(f)\n",
    "\n",
    "with open('ranking_data_shad/train_rubric_information.json') as f:\n",
    "    rubric_info = json.load(f)\n",
    "\n",
    "train = pd.read_csv('ranking_data_shad/train.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/27697 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9747fe53a9f465ead1d816fda4f4de7"
      },
      "application/json": {
       "n": 0,
       "total": 27697,
       "elapsed": 0.02211451530456543,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "org_features = []\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "for org_id, org in tqdm(org_info.items()):\n",
    "    lon, lat = org['address']['pos']['coordinates']\n",
    "\n",
    "    rubrics_num = len(org['rubrics'])\n",
    "    region_id = org['address']['geo_id']\n",
    "\n",
    "    working_days_num = 0\n",
    "    for interval in org['work_intervals']:\n",
    "        if interval['day'] == 'weekdays':\n",
    "            working_days_num += 5\n",
    "        elif interval['day'] == 'everyday':\n",
    "            working_days_num += 7\n",
    "        else:\n",
    "            working_days_num += 1\n",
    "\n",
    "    region_code = org['address']['region_code']\n",
    "\n",
    "    org_features.append({\n",
    "        'org_id': org_id,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'rubrics_num': rubrics_num,\n",
    "        'org_region_id': region_id,\n",
    "        'working_days_num': working_days_num,\n",
    "        'region_code': region_code\n",
    "    })\n",
    "\n",
    "orgs_df = pd.DataFrame(org_features)\n",
    "orgs_df['org_id'] = orgs_df['org_id'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "def one_hot_encode(df, feature_column, trashhold, prefix, drop_original_column=False):\n",
    "    df = df.copy()\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    df_oht = pd.DataFrame(enc.fit_transform(df[feature_column].values.reshape(-1, 1)), columns=enc.categories_)\n",
    "    for column in df_oht.columns:\n",
    "        if df_oht[column].mean() > trashhold:\n",
    "            df[f'{prefix}{column}'] = df_oht[column]\n",
    "    if drop_original_column:\n",
    "        df.drop(columns=[feature_column], inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "orgs_df = one_hot_encode(orgs_df, 'org_region_id', 0.03, 'is_region_', drop_original_column=False)\n",
    "orgs_df = one_hot_encode(orgs_df, 'region_code', 0.03, 'is_region_code_', drop_original_column=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['query'] = train['query'].str.findall('\\w+').str.join(' ').str.lower()\n",
    "train['org_name'] = train['org_name'].str.findall('\\w+').str.join(' ').str.lower()\n",
    "train['window_center'] = train['window_center'].str.split(',').str[::-1]\n",
    "train['window_size'] = train['window_size'].apply(lambda x: np.sqrt(float(x.split(',')[0])**2 + float(x.split(',')[1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "train = pd.merge(train, orgs_df, on='org_id')\n",
    "train['org_point'] = train['lat'].astype(str) + ',' + train['lon'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=915), Label(value='0 / 915'))), HB…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca0085f3df32485da18fdfa13c3bcb7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['distance'] = train.parallel_apply(lambda row: distance(row['window_center'], row['org_point']).km, axis=1)\n",
    "train['word_count_query'] = train['query'].str.split().str.len()\n",
    "train['word_count_org'] = train['org_name'].str.split().str.len()\n",
    "train['is_same_region'] = train['region'] == train['org_region_id']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/29274 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cd26a25684e4bcda8621dc5888af4a8"
      },
      "application/json": {
       "n": 0,
       "total": 29274,
       "elapsed": 0.023636579513549805,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29274 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27eb5aba67894cdd90a317ac6fa3d4ab"
      },
      "application/json": {
       "n": 0,
       "total": 29274,
       "elapsed": 0.021679401397705078,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29274 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "449ffb01e1a84ef1a598616b671855a9"
      },
      "application/json": {
       "n": 0,
       "total": 29274,
       "elapsed": 0.022514820098876953,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29274 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f754caee3bd74ee3a0099ecb4430e635"
      },
      "application/json": {
       "n": 0,
       "total": 29274,
       "elapsed": 0.022053241729736328,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29274 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0aaf6e5779624ed29340cef0ac66e4d7"
      },
      "application/json": {
       "n": 0,
       "total": 29274,
       "elapsed": 0.023224353790283203,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29274 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca35047464874fd89045ba5199a187b9"
      },
      "application/json": {
       "n": 0,
       "total": 29274,
       "elapsed": 0.023158788681030273,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_intersection(row, n):\n",
    "    query_gramms = set(ngrams(row['query'].split(), n))\n",
    "    org_gramms = set(ngrams(row['org_name'].split(), n))\n",
    "\n",
    "    return len(query_gramms & org_gramms)\n",
    "def find_jaccard(row, n):\n",
    "    query_gramms = set(ngrams(row['query'].split(), n))\n",
    "    org_gramms = set(ngrams(row['org_name'].split(), n))\n",
    "\n",
    "    return len(query_gramms & org_gramms) / (len(org_gramms - query_gramms) + len(query_gramms - org_gramms) + 0.001)\n",
    "for word_count in (1, 2, 3):\n",
    "    apply_intersection = partial(find_intersection, n=word_count)\n",
    "    train[f'intersection_{word_count}_gramms']= train.progress_apply(apply_intersection, axis=1)\n",
    "\n",
    "    apply_jaccard = partial(find_jaccard, n=word_count)\n",
    "    train[f'jaccard_{word_count}_gramms']= train.progress_apply(apply_jaccard, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=915), Label(value='0 / 915'))), HB…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "428f409c7bbe422eaf4782de34e4a1ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=915), Label(value='0 / 915'))), HB…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b343c305e4f4b6690b571dcf30f5652"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def detect_language(string):\n",
    "    try:\n",
    "        return detect(string)\n",
    "    except Exception as e:\n",
    "        return 'unk'\n",
    "\n",
    "train['org_name_language'] = train['org_name'].parallel_apply(detect_language)\n",
    "train['query_language'] = train['query'].parallel_apply(detect_language)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "train = one_hot_encode(train, 'query_language', 0.05, 'is_query_', drop_original_column=False)\n",
    "train = one_hot_encode(train, 'org_name_language', 0.05, 'is_org_name_', drop_original_column=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранжирование\n",
    "\n",
    "![](http://i.imgur.com/2QnD2nF.jpg)\n",
    "\n",
    "Задачу поискового ранжирования можно описать следующим образом: имеется множество документов $d \\in D$ и множество запросов $q \\in Q$. Требуется оценить *степень релевантности* документа по отношению к запросу: $(q, d) \\mapsto r$, относительно которой будет производиться ранжирование. Для восстановления этой зависимости используются методы машинного обучения. Обычно используется три типа:\n",
    " - признаки запроса $q$, например: мешок слов текста запроса, его длина, ...\n",
    " - документа $d$, например: значение PageRank, мешок слов, доменное имя, ...\n",
    " - пары $(q, d)$, например: число вхождений фразы из запроса $q$ в документе $d$, ...\n",
    "\n",
    "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
    "### Подходы к решению задачи ранжирования\n",
    "Существуют 3 основных подхода, различие между которыми в используемой функции потерь:\n",
    "  \n",
    "1. **Pointwise подход**. В этом случае рассматривается *один объект* (в случае поискового ранжирования - конкретный документ) и функция потерь считается только по нему. Любой стандартный классификатор или регрессор может решать pointwise задачу ранжирования, обучившись предсказывать значение таргета. Итоговое ранжирование получается после сортировки документов к одному запросу по предсказанию такой модели.\n",
    "2. **Pairwise подход**. В рамках данной модели функция потерь вычисляется по *паре объектов*. Другими словами, функция потерь штрафует модель, если отражированная этой моделью пара документов оказалась в неправильном порядке.\n",
    "3. **Listwise подход**. Этот подход использует все объекты для вычисления функции потерь, стараясь явно оптимизировать правильный порядок.\n",
    "\n",
    "### Оценка качества\n",
    "\n",
    "Для оценивания качества ранжирования найденных документов в поиске используются асессорские оценки. Само оценивание происходит на скрытых от обучения запросах $Queries$. Для этого традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
    "Для одного запроса DCG считается следующим образом:\n",
    "$$ DCG = \\sum_{i=1}^P\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
    "\n",
    "где $P$ — число документов в поисковой выдаче, $rel_i$ — релевантность (асессорская оценка) документа, находящегося на i-той позиции.\n",
    "\n",
    "*IDCG* — идеальное (наибольшее из возможных) значение *DCG*, может быть получено путем ранжирования документов по убыванию асессорских оценок.\n",
    "\n",
    "Итоговая формула для расчета *nDCG*:\n",
    "\n",
    "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
    "\n",
    "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
    "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
    "\n",
    "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках нашей задачи «документом» будет являться организация.\n",
    "\n",
    "Разбейте обучающую выборку на обучение и контроль в соотношении 70 / 30. Обратите внимание, что разбивать необходимо множество запросов, а не строчки датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = train['query_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "queries_train, queries_test = train_test_split(queries, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "test = train[train['query_id'].isin(set(queries_test))].reset_index()\n",
    "train = train[train['query_id'].isin(set(queries_train))].reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "train.sort_values('query_id', inplace=True)\n",
    "test.sort_values('query_id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее рассмотрим несколько подходов предсказания релевантности. Для оценивания качества моделей используйте метрику nDCG на контроле. В случае подбора гиперпараметров используйте кросс-валидацию по 5 блокам, где разбиение должно быть по запросам, а не строчкам датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ранжируем с XGBoost и CatBoost\n",
    "\n",
    "XGBoost имеет несколько функций потерь для решения задачи ранжирования:\n",
    "1. **reg:linear** — данную функцию потерь можно использовать для решения задачи ранжирование *pointwise* подходом.\n",
    "2. **rank:pairwise** — в качестве *pairwise* модели в XGBoost реализован [RankNet](http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf), в котором минимизируется гладкий функционал качества ранжирования: $$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = log(1 + e^{-M}), $$ где $ a(x) $ - функция ранжирования. Суммирование ведется по всем парам объектов, для которых определено отношение порядка, например, для пар документов, показанных по одному запросу. Таким образом функция потерь штрафует за то, что пара объектов неправильно упорядочена.\n",
    "3. **rank:map, rank:ndcg** — реализация [LambdaRank](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) для двух метрик: [MAP](https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision) и **nDCG**. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как **nDCG**,  нужно домножить градиент функционала $ Obj(a) $ на значение $\\Delta NDCG_{ij} $ — изменение значения функционала качества при замене $x_i$ на $ x_j$.  Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса *listwise* моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализованные в CatBoost ранжирующие функции потерь можной найти [здесь](https://catboost.ai/docs/concepts/loss-functions-ranking.html#groupwise-metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла) Задание 2.** Попробуйте различные функции потерь (регрессионные и ранжирующие) для моделей XGBoost и CatBoost. Настройте основные параметры моделей (глубина, кол-во деревьев, глубина, скорость обучения, регуляризация).  \n",
    "Сравните построенные модели с точки зрения метрики nDCG на контроле и проанализируйте полученные результаты:\n",
    "  - какая модель работает лучше всего для данной задачи? \n",
    "  - в чем достоинства/недостатки каждой? \n",
    "  - сравните модели между собой: \n",
    "   - получается ли сравнимое качество линейного pointwise подхода с остальными моделями? \n",
    "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "useful_columns = ['query_id', 'window_size', 'relevance', 'rubrics_num', 'working_days_num', 'is_region_(2,)',\n",
    "       'is_region_(143,)', 'is_region_(213,)', \"is_region_code_('RU',)\",\n",
    "       \"is_region_code_('TR',)\", \"is_region_code_('UA',)\",\n",
    "       'distance', 'word_count_query', 'word_count_org', 'is_same_region',\n",
    "       'intersection_1_gramms', 'jaccard_1_gramms', 'intersection_2_gramms',\n",
    "       'jaccard_2_gramms', 'intersection_3_gramms', 'jaccard_3_gramms', \"is_query_('bg',)\",\n",
    "       \"is_query_('mk',)\", \"is_query_('ru',)\", \"is_query_('tr',)\",\n",
    "       \"is_org_name_('bg',)\", \"is_org_name_('mk',)\", \"is_org_name_('ru',)\",\n",
    "       \"is_org_name_('tr',)\", \"is_org_name_('uk',)\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "def score_for_xgb(self, X, y):\n",
    "    predict = self.predict(X)\n",
    "    scores = []\n",
    "    for query_id in X['query_id'].unique():\n",
    "        mask = X['query_id'] == query_id\n",
    "\n",
    "        if sum(mask) == 1:\n",
    "            scores.append(1)\n",
    "            continue\n",
    "\n",
    "        score = ndcg_score(np.asarray([y[mask]]),\n",
    "                       np.asarray([predict[mask]]))\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "def fit_xgboost(train_df: pd.DataFrame, model_class, objective, qid_column=None):\n",
    "    params = {\n",
    "        'max_depth': [2, 3, 4, 5, 6],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [25, 50, 75, 100],\n",
    "        'lambda': [0, 1],\n",
    "        'objective':[objective]\n",
    "        }\n",
    "    XGBoost = model_class()\n",
    "    model = GridSearchCV(XGBoost, params, verbose=1, n_jobs=-1, scoring=score_for_xgb)\n",
    "    if qid_column is not None:\n",
    "        model.fit(train_df.drop(columns=['relevance']), train_df['relevance'], qid=qid_column)\n",
    "    else:\n",
    "        model.fit(train_df.drop(columns=['relevance']), train_df['relevance'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7787615582648851"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fit_xgboost(train_df=train[useful_columns], model_class=xgb.XGBRegressor, objective='reg:squarederror')\n",
    "score_for_xgb(model, test[useful_columns].drop(columns='relevance'), test['relevance'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7790807761739877"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fit_xgboost(train_df=train[useful_columns], model_class=xgb.XGBRanker, objective='rank:pairwise', qid_column=train['query_id'])\n",
    "score_for_xgb(model, test[useful_columns].drop(columns='relevance'), test['relevance'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6651910238443524"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fit_xgboost(train_df=train[useful_columns], model_class=xgb.XGBRanker, objective='rank:ndcg', qid_column=train['query_id'])\n",
    "score_for_xgb(model, test[useful_columns].drop(columns='relevance'), test['relevance'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=train[useful_columns].drop(columns=['relevance', 'query_id']).values,\n",
    "    label=train['relevance'].values,\n",
    "    group_id=train['query_id'].values\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "     data=test[useful_columns].drop(columns=['relevance', 'query_id']).values,\n",
    "    label=test['relevance'].values,\n",
    "    group_id=test['query_id'].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def fit_catboost(trial, loss_function):\n",
    "    params = {\n",
    "        'depth': trial.suggest_categorical('depth', [2, 3, 4, 5, 6]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.05, 0.1]),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [25, 50, 75, 100]),\n",
    "        'reg_lambda': trial.suggest_categorical('reg_lambda', [0, 1]),\n",
    "        }\n",
    "\n",
    "    catboost = CatBoostRanker(loss_function=loss_function, verbose=False, **params)\n",
    "\n",
    "    catboost.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "    return score_for_xgb(catboost, test[categorical_columns + useful_columns].drop(columns=['relevance']), test['relevance'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "      window_size  rubrics_num  working_days_num  is_region_(2,)  \\\n0        0.019706            1                 7             0.0   \n32       0.019706            1                 7             0.0   \n31       0.019706            1                 0             0.0   \n30       0.019706            1                 7             0.0   \n29       0.019706            4                 7             0.0   \n...           ...          ...               ...             ...   \n8861     0.042153            2                 7             1.0   \n8860     0.042153            1                 7             0.0   \n8872     0.042153            2                 5             0.0   \n8865     0.042153            2                 6             1.0   \n8873     0.042153            3                 5             1.0   \n\n      is_region_(143,)  is_region_(213,)  is_region_code_('RU',)  \\\n0                  0.0               0.0                     0.0   \n32                 0.0               0.0                     0.0   \n31                 0.0               0.0                     0.0   \n30                 0.0               0.0                     0.0   \n29                 0.0               0.0                     0.0   \n...                ...               ...                     ...   \n8861               0.0               0.0                     1.0   \n8860               0.0               0.0                     1.0   \n8872               0.0               0.0                     1.0   \n8865               0.0               0.0                     1.0   \n8873               0.0               0.0                     1.0   \n\n      is_region_code_('TR',)  is_region_code_('UA',)    distance  ...  \\\n0                        0.0                     1.0    0.413171  ...   \n32                       0.0                     1.0    0.390185  ...   \n31                       0.0                     1.0    0.509190  ...   \n30                       0.0                     1.0    0.606463  ...   \n29                       0.0                     1.0    0.757159  ...   \n...                      ...                     ...         ...  ...   \n8861                     0.0                     0.0    0.024858  ...   \n8860                     0.0                     0.0  828.119269  ...   \n8872                     0.0                     0.0   25.256190  ...   \n8865                     0.0                     0.0    0.229120  ...   \n8873                     0.0                     0.0   13.905235  ...   \n\n      jaccard_3_gramms  is_query_('bg',)  is_query_('mk',)  is_query_('ru',)  \\\n0                  0.0               0.0               0.0               1.0   \n32                 0.0               0.0               0.0               1.0   \n31                 0.0               0.0               0.0               1.0   \n30                 0.0               0.0               0.0               1.0   \n29                 0.0               0.0               0.0               1.0   \n...                ...               ...               ...               ...   \n8861               0.0               0.0               0.0               1.0   \n8860               0.0               0.0               0.0               1.0   \n8872               0.0               0.0               0.0               1.0   \n8865               0.0               0.0               0.0               1.0   \n8873               0.0               0.0               0.0               1.0   \n\n      is_query_('tr',)  is_org_name_('bg',)  is_org_name_('mk',)  \\\n0                  0.0                  0.0                  0.0   \n32                 0.0                  0.0                  0.0   \n31                 0.0                  0.0                  1.0   \n30                 0.0                  0.0                  0.0   \n29                 0.0                  0.0                  0.0   \n...                ...                  ...                  ...   \n8861               0.0                  0.0                  0.0   \n8860               0.0                  0.0                  0.0   \n8872               0.0                  0.0                  0.0   \n8865               0.0                  0.0                  0.0   \n8873               0.0                  0.0                  0.0   \n\n      is_org_name_('ru',)  is_org_name_('tr',)  is_org_name_('uk',)  \n0                     1.0                  0.0                  0.0  \n32                    0.0                  0.0                  1.0  \n31                    0.0                  0.0                  0.0  \n30                    0.0                  0.0                  1.0  \n29                    1.0                  0.0                  0.0  \n...                   ...                  ...                  ...  \n8861                  1.0                  0.0                  0.0  \n8860                  1.0                  0.0                  0.0  \n8872                  1.0                  0.0                  0.0  \n8865                  1.0                  0.0                  0.0  \n8873                  1.0                  0.0                  0.0  \n\n[8874 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window_size</th>\n      <th>rubrics_num</th>\n      <th>working_days_num</th>\n      <th>is_region_(2,)</th>\n      <th>is_region_(143,)</th>\n      <th>is_region_(213,)</th>\n      <th>is_region_code_('RU',)</th>\n      <th>is_region_code_('TR',)</th>\n      <th>is_region_code_('UA',)</th>\n      <th>distance</th>\n      <th>...</th>\n      <th>jaccard_3_gramms</th>\n      <th>is_query_('bg',)</th>\n      <th>is_query_('mk',)</th>\n      <th>is_query_('ru',)</th>\n      <th>is_query_('tr',)</th>\n      <th>is_org_name_('bg',)</th>\n      <th>is_org_name_('mk',)</th>\n      <th>is_org_name_('ru',)</th>\n      <th>is_org_name_('tr',)</th>\n      <th>is_org_name_('uk',)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.019706</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.413171</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.019706</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.390185</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.019706</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.509190</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.019706</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.606463</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.019706</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.757159</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8861</th>\n      <td>0.042153</td>\n      <td>2</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.024858</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8860</th>\n      <td>0.042153</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>828.119269</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8872</th>\n      <td>0.042153</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.256190</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8865</th>\n      <td>0.042153</td>\n      <td>2</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.229120</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8873</th>\n      <td>0.042153</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.905235</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8874 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[useful_columns].drop(columns=['relevance', 'query_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7644994316070595"
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(functools.partial(fit_catboost, loss_function='RMSE'), n_trials=50)\n",
    "study.best_trial.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7609800092533126"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(functools.partial(fit_catboost, loss_function='YetiRank'), n_trials=50)\n",
    "study.best_trial.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7496550772875981"
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(functools.partial(fit_catboost, loss_function='YetiRankPairwise'), n_trials=50)\n",
    "study.best_trial.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "лучше все себя показал XGBoost c функцией pairwise\n",
    "\n",
    "XGBoost себя в целом лучше показал чем CatBoost, хотя возможно это потому что я его подольше тюнил\n",
    "\n",
    "регрессия почти также хоршо дает скор как и pairwise. с одной стороны регрессия лучше попадает когда ситуация какая-то вырожденная например если одна организация крутая а дркгие все фигня. с другой сторон регрессия решает более сложную задачу теми же методами, поэтому оптимизирует хуже\n",
    "\n",
    "удивительно что 'rank:ndcg' для XGBoost совсем плохо работает хотя казалось бы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(1 балл) Задание 3.** Одним из основных преимуществ CatBoost'a является обработка категориальных факторов «из коробки». Добавьте в датасет различные категориальные факторы из данных и обучите заново CatBoost модели. Улучшилось ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['region', 'org_id', 'org_region_id', 'region_code']\n",
    "for column in categorical_columns:\n",
    "    test[column] = test[column].astype(\"string\")\n",
    "    train[column] = train[column].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=train[categorical_columns + useful_columns].drop(columns=['relevance']),\n",
    "    cat_features=categorical_columns,\n",
    "    label=train['relevance'],\n",
    "    group_id=train['query_id']\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "     data=test[categorical_columns + useful_columns].drop(columns=['relevance']),\n",
    "    cat_features=categorical_columns,\n",
    "    label=test['relevance'],\n",
    "    group_id=test['query_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "data": {
      "text/plain": "region           string\norg_id           string\norg_region_id    string\nregion_code      string\ndtype: object"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "region           string\norg_id           string\norg_region_id    string\nregion_code      string\ndtype: object"
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[categorical_columns].dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7808536265644548"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(functools.partial(fit_catboost, loss_function='RMSE'), n_trials=50)\n",
    "study.best_trial.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "data": {
      "text/plain": "0.785022387001286"
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(functools.partial(fit_catboost, loss_function='YetiRank'), n_trials=50)\n",
    "study.best_trial.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7829480674697985"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(functools.partial(fit_catboost, loss_function='YetiRankPairwise'), n_trials=50)\n",
    "study.best_trial.value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "о, куль\n",
    "стало лучше\n",
    "даже не ожидал как-то\n",
    "все-таки не просто так там в яндексе сидят"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла) Задание 5.** Постройте любую нейросетевую ранжирующую модель\n",
    "с помощью tensorflow_ranking или используйте dssm модель на tensorflow/keras/torch по аналогии с моделями на практическом занятии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "my_env",
   "language": "python",
   "display_name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
